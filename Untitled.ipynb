{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b15d4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import gc, os, pickle, cv2\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from sampling.kcenter_greedy import KCenterGreedy\n",
    "from sklearn.random_projection import SparseRandomProjection\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import torch\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b10142ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "class BackBoneModel(nn.Module):\n",
    "    def __init__(self, args):\n",
    "        super().__init__()\n",
    "        self.args = args\n",
    "        self.features = []\n",
    "        self.pretrained_model = None\n",
    "\n",
    "    def hook_t(self, module, input, output):\n",
    "        self.features.append(output)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.features = []\n",
    "        _ = self.pretrained_model(x)\n",
    "        return self.features\n",
    "\n",
    "    def eval(self):\n",
    "        self.pretrained_model.eval()\n",
    "\n",
    "\n",
    "class WideResNet50(BackBoneModel):\n",
    "    def __init__(self, args):\n",
    "        super().__init__(args)\n",
    "        self.pretrained_model = torch.hub.load('pytorch/vision:v0.8.2',\n",
    "                                               'wide_resnet50_2', pretrained=True)\n",
    "\n",
    "        for param in self.pretrained_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.pretrained_model.layer2[-1].register_forward_hook(self.hook_t)\n",
    "        self.pretrained_model.layer3[-1].register_forward_hook(self.hook_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ed3132",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "# import faiss\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.metrics import (roc_curve, \n",
    "                             roc_auc_score, \n",
    "                             recall_score,\n",
    "                             precision_score, \n",
    "                             confusion_matrix, \n",
    "                             f1_score, accuracy_score)\n",
    "from torch.nn import functional as F\n",
    "\n",
    "\n",
    "def min_max_norm(image, min_=None, max_=None):\n",
    "    a_min = image.min() if min_ is None else min_\n",
    "    a_max = image.max() if max_ is None else max_\n",
    "    return (image - a_min) / (a_max - a_min)\n",
    "\n",
    "\n",
    "def embedding_concat(x, y):\n",
    "    B, C1, H1, W1 = x.size()\n",
    "    _, C2, H2, W2 = y.size()\n",
    "    s = int(H1 / H2)\n",
    "    x = F.unfold(x, kernel_size=s, dilation=1, stride=s)\n",
    "    x = x.view(B, C1, -1, H2, W2)\n",
    "    z = torch.zeros(B, C1 + C2, x.size(2), H2, W2)\n",
    "    for i in range(x.size(2)):\n",
    "        z[:, :, i, :, :] = torch.cat((x[:, :, i, :, :], y), 1)\n",
    "    z = z.view(B, -1, H2 * W2)\n",
    "    z = F.fold(z, kernel_size=s, output_size=(H1, W1), stride=s)\n",
    "    return z\n",
    "\n",
    "\n",
    "def reshape_embedding(embedding):\n",
    "    embedding_list = []\n",
    "    for k in range(embedding.shape[0]):\n",
    "        for i in range(embedding.shape[2]):\n",
    "            for j in range(embedding.shape[3]):\n",
    "                embedding_list.append(embedding[k, :, i, j])\n",
    "    return embedding_list\n",
    "\n",
    "\n",
    "def features_to_embedding(features, kernel_size=3, stride=1, padding=1):\n",
    "    embeddings = []\n",
    "    for feature in features:\n",
    "        m = torch.nn.AvgPool2d(kernel_size=kernel_size, stride=stride, padding=padding)\n",
    "        embeddings.append(m(feature))\n",
    "\n",
    "    embeddings_num = len(embeddings)\n",
    "    for index in range(embeddings_num):\n",
    "        if index == 0:\n",
    "            embedding = embeddings[index]\n",
    "        else:\n",
    "            b1, c1, h1, w1 = embedding.shape\n",
    "            b2, c2, h2, w2 = embeddings[index].shape\n",
    "            if h1 % h2 != 0:\n",
    "                diff_h = abs(h1 - (h2 * 2))\n",
    "                embedding = torch.nn.ZeroPad2d((diff_h, 0, diff_h, 0))(embedding)\n",
    "            embedding = embedding_concat(embedding, embeddings[index]).cuda()\n",
    "    reshaped_embedding = reshape_embedding(np.array(embedding.cpu()))\n",
    "    return reshaped_embedding\n",
    "\n",
    "\n",
    "def distance_matrix(x, y=None, p=2):  # pairwise distance of vectors\n",
    "    y = x if type(y) == type(None) else y\n",
    "\n",
    "    n = x.size(0)\n",
    "    m = y.size(0)\n",
    "    d = x.size(1)\n",
    "\n",
    "    x = x.unsqueeze(1).expand(n, m, d)\n",
    "    y = y.unsqueeze(0).expand(n, m, d)\n",
    "    dist = torch.pow(x - y, p).sum(dim=2)\n",
    "    return dist\n",
    "\n",
    "\n",
    "def tensor_from_numpy(data):\n",
    "    \"\"\"\n",
    "    numpyからPyTorchのTensorを作成する\n",
    "    :param data:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    d = torch.from_numpy(data)\n",
    "    if torch.cuda.is_available():\n",
    "        d = d.cuda()\n",
    "    return d\n",
    "\n",
    "\n",
    "def get_knn_distance_faiss(coreset, test_data, k, batch_size=512):\n",
    "    \"\"\"\n",
    "    coresetとtest_dataの最短距離を上位k個求める\n",
    "    :param coreset:\n",
    "    :param test_data:\n",
    "    :param k:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    cpu_index = faiss.IndexFlatL2(coreset.shape[1])\n",
    "    index = faiss.index_cpu_to_all_gpus(cpu_index)\n",
    "    index.add(coreset)\n",
    "    distance, index_info = index.search(test_data, k)\n",
    "    return distance\n",
    "\n",
    "\n",
    "def get_knn_distance(coreset, test_data, k, batch_size=512):\n",
    "    \"\"\"\n",
    "    coresetとtest_dataの最短距離を上位k個求める\n",
    "    :param coreset:\n",
    "    :param test_data:\n",
    "    :param k:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    p = 2\n",
    "    coreset_tsr = tensor_from_numpy(coreset)\n",
    "    test_data_tsr = tensor_from_numpy(test_data)\n",
    "\n",
    "    max_test_data_num = test_data_tsr.shape[0]\n",
    "    max_loop_num = int(np.ceil(max_test_data_num / batch_size))\n",
    "\n",
    "    dist = None\n",
    "    for index in range(max_loop_num):\n",
    "        start = index * batch_size\n",
    "        end = (index + 1) * batch_size\n",
    "        dist_m = distance_matrix(test_data_tsr[start:end], coreset_tsr, p=2)\n",
    "        dist_batch = dist_m ** (1 / p)\n",
    "        if dist is None:\n",
    "            dist = dist_batch\n",
    "        else:\n",
    "            dist = torch.cat([dist, dist_batch], dim=0)\n",
    "\n",
    "    dist_knn = dist.topk(k, largest=False)\n",
    "    dist_knn = dist_knn[0].cpu().detach().numpy()\n",
    "    return dist_knn\n",
    "\n",
    "\n",
    "def denormalization(x):\n",
    "    mean = np.array([0.485, 0.456, 0.406])\n",
    "    std = np.array([0.229, 0.224, 0.225])\n",
    "    x = (((x.transpose(1, 2, 0) * std) + mean) * 255.).astype(np.uint8)\n",
    "    return x\n",
    "\n",
    "\n",
    "def calc_roc_best_score(fpr, tpr, thresholds):\n",
    "    \"\"\"\n",
    "    fpr, tprの相乗平均(幾何平均)を最大にする閾値とindexを返す\n",
    "    :param fpr:\n",
    "    :param tpr:\n",
    "    :param thresholds:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    gmeans = np.sqrt(tpr * (1 - fpr))\n",
    "    ix = np.argmax(gmeans)\n",
    "    roc_threshold = thresholds[ix]\n",
    "    return roc_threshold, ix\n",
    "\n",
    "def to_labels(pos_probs, threshold):\n",
    "    return (pos_probs >= threshold).astype('int')\n",
    "\n",
    "def specificity_score(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    特異度を返す\n",
    "    :param y_true:\n",
    "    :param y_pred:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).flatten()\n",
    "    return tn / (tn + fp)\n",
    "\n",
    "\n",
    "def calc_metrics(img_scores, gt_list):\n",
    "    \"\"\"\n",
    "    閾値を0.1刻みで変化させ、recall, specificity, precisionを求める\n",
    "    :param img_scores: 0〜１に正規化されている必要がある\n",
    "    :param gt_list: 0〜１に正規化されている必要がある\n",
    "    :return: thresholds, recall, specificity, precision\n",
    "    \"\"\"\n",
    "    thresholds = np.arange(0, 1.01, 0.01)\n",
    "    recall = np.array([recall_score(gt_list, to_labels(img_scores, th_i)) for th_i in thresholds])\n",
    "    specificity = np.array([specificity_score(gt_list, to_labels(img_scores, th_i)) for th_i in thresholds])\n",
    "    precision = np.array([precision_score(gt_list, to_labels(img_scores, th_i)) for th_i in thresholds])\n",
    "    return thresholds, recall, specificity, precision\n",
    "\n",
    "\n",
    "def calc_f1_score_precision_recall(recall, precision, thresholds):\n",
    "    \"\"\"\n",
    "    recallとprecisionの調和平均を求め、最大の値とindex, thresholdを返す\n",
    "    :param recall:\n",
    "    :param precision:\n",
    "    :param thresholds:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    a = 2 * precision * recall\n",
    "    b = precision + recall\n",
    "    f1_precision_recall = np.divide(a, b, out=np.zeros_like(a), where=b != 0)\n",
    "    idx = np.argmax(f1_precision_recall)\n",
    "    pr_threshold = thresholds[idx]\n",
    "    pr_best_f1score = f1_precision_recall[idx]\n",
    "    return pr_threshold, pr_best_f1score, idx\n",
    "\n",
    "\n",
    "def calc_f1_score_specificity_recall(recall, specificity, thresholds):\n",
    "    c = 2 * specificity * recall\n",
    "    d = specificity + recall\n",
    "    f1_specificity_recall = np.divide(c, d, out=np.zeros_like(c), where=d != 0)\n",
    "    idx = np.argmax(f1_specificity_recall)\n",
    "    sr_threshold = thresholds[idx]\n",
    "    sr_best_f1score = f1_specificity_recall[idx]\n",
    "    return sr_threshold, sr_best_f1score, idx\n",
    "\n",
    "\n",
    "def get_best_threshold(scores, labels, thr):\n",
    "    best_thr = -1\n",
    "    best_f1 = -1\n",
    "    for t in thr:\n",
    "        pred_label = np.copy(labels)\n",
    "        good_index = np.where(scores < t)\n",
    "        pred_label[good_index] = 0\n",
    "        bad_index = np.where(t <= scores)\n",
    "        pred_label[bad_index] = 1\n",
    "\n",
    "        f1 = f1_score(labels, pred_label)\n",
    "        # cm = confusion_matrix(labels, pred_label)\n",
    "        # acc = accuracy_score(labels, pred_label)\n",
    "        # pre = precision_score(labels, pred_label)\n",
    "        # rec = recall_score(labels, pred_label)\n",
    "\n",
    "        if best_f1 < f1:\n",
    "            best_f1 = f1\n",
    "            best_thr = t\n",
    "\n",
    "    return best_f1, best_thr\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daaa772d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "544e2752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# noinspection PyAttributeOutsideInit\n",
    "class PatchCore(pl.LightningModule):\n",
    "    def __init__(self, args, category):\n",
    "        super(PatchCore, self).__init__()\n",
    "        self.args = args\n",
    "        self.category = category\n",
    "        \n",
    "        # https://pytorch-lightning.readthedocs.io/en/latest/common/hyperparameters.html#save-hyperparameters\n",
    "#         self.save_hyperparameters(self.args)\n",
    "        self.init_results_list()\n",
    "\n",
    "        self.inv_normalize = transforms.Normalize(\n",
    "            mean=[-0.485/0.229, -0.456/0.224, -0.406/0.255],\n",
    "            std=[1/0.229, 1/0.224, 1/0.255])\n",
    "\n",
    "        self.backbone_model = globals()[self.args.backbone](self.args)\n",
    "        # self.knn = None\n",
    "\n",
    "        # dummy\n",
    "        self.criterion = torch.nn.MSELoss(reduction='sum')\n",
    "\n",
    "    def init_results_list(self):\n",
    "        self.gt_pixel = []\n",
    "        self.score_pixel = []\n",
    "        self.best_thr_pixel = []\n",
    "        self.gt_image = []\n",
    "        self.score_image = []\n",
    "        self.img_path_list = []\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return None\n",
    "\n",
    "    def forward(self, x_t):\n",
    "        features = self.backbone_model(x_t)\n",
    "        return features\n",
    "\n",
    "    def on_train_start(self):\n",
    "        self.backbone_model.eval()\n",
    "        self.embedding_list = []\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, _, _, file_name, _ = batch\n",
    "        features = self(x)\n",
    "        # https://gitlab.com/chowagiken/toyota_kinuura/anomaly_detection/patch_core/-/blob/main/model/tensor_util.py#L40\n",
    "        embedding = features_to_embedding(features, \n",
    "                                          self.args.kernel_size, \n",
    "                                          self.args.stride, self.args.padding)\n",
    "        self.embedding_list.extend(embedding)\n",
    "\n",
    "    def training_epoch_end(self, outputs):\n",
    "        if (self.args.num_epochs - 1) == self.current_epoch:\n",
    "            self.embedding_coreset = self.create_coreset(self.embedding_list)\n",
    "            gc.collect()\n",
    "\n",
    "    def on_test_start(self):\n",
    "        self.init_results_list()\n",
    "        self.sample_path = os.path.join(self.logger.log_dir, 'sample')\n",
    "        os.makedirs(self.sample_path, exist_ok=True)\n",
    "\n",
    "        coreset_file_path = os.path.join(self.args.model_path, f'{self.category}.pickle')\n",
    "        self.load_model_data = pickle.load(open(coreset_file_path, 'rb'))\n",
    "        self.embedding_coreset = self.load_model_data['model_data']\n",
    "        # self.embedding_coreset = pickle.load(open(coreset_file_path, 'rb'))\n",
    "        # self.knn = FaissKNeighbors(self.embedding_coreset, k=self.args.n_neighbors)\n",
    "        # self.score_patches_array = None\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        x, gt, label, file_name, x_type = batch\n",
    "\n",
    "        features = self(x)\n",
    "        embedding = features_to_embedding(features)\n",
    "        embedding_test = np.array(embedding)\n",
    "\n",
    "        # score_patches, index_info = self.knn.search(embedding_test)\n",
    "        \n",
    "        # score_patches = get_knn_distance_faiss(\n",
    "        #     self.embedding_coreset,\n",
    "        #     embedding_test,\n",
    "        #     k=self.args.n_neighbors,\n",
    "        #     batch_size=self.args.calc_distance_batch_size)\n",
    "\n",
    "        score_patches = get_knn_distance(\n",
    "            self.embedding_coreset,\n",
    "            embedding_test,\n",
    "            k=self.args.n_neighbors,\n",
    "            batch_size=self.args.calc_distance_batch_size)\n",
    "\n",
    "        # Image-level score\n",
    "        nearest_distance = score_patches[np.argmax(score_patches[:, 0])]\n",
    "        w = (1 - (np.max(np.exp(nearest_distance)) / np.sum(np.exp(nearest_distance))))\n",
    "        \n",
    "        if math.isnan(w):\n",
    "            # distanceが大きすぎる場合の暫定処理\n",
    "            w = (1 - (np.max(np.exp(nearest_distance * (1 / 16))) / np.sum(np.exp(nearest_distance * (1 / 16)))))\n",
    "        \n",
    "        score = w * max(score_patches[:, 0])\n",
    "\n",
    "        # pixel level anomaly map\n",
    "        reshape_size = np.sqrt(score_patches[:, 0].shape)[0].astype(np.int)\n",
    "        anomaly_map = score_patches[:, 0].reshape((reshape_size, reshape_size))\n",
    "        anomaly_map_resized = cv2.resize(anomaly_map, (self.args.input_size, self.args.input_size))\n",
    "        anomaly_map_resized_blur = gaussian_filter(anomaly_map_resized, sigma=4)\n",
    "        anomaly_map_norm = min_max_norm(anomaly_map_resized_blur)\n",
    "\n",
    "        # set results\n",
    "        gt_np = gt.cpu().numpy()[0, 0].astype(int)\n",
    "        self.gt_pixel.append(gt_np)\n",
    "        # self.gt_pixel.append(gt_np.ravel())\n",
    "        # self.gt_pixel.extend(gt_np.ravel())\n",
    "\n",
    "        self.score_pixel.append(anomaly_map_resized_blur)\n",
    "        # self.score_pixel.append(anomaly_map_resized_blur)\n",
    "        # self.score_pixel.append(anomaly_map_resized_blur.ravel())\n",
    "        # self.score_pixel.extend(anomaly_map_resized_blur.ravel())\n",
    "\n",
    "        if 1 < np.unique(gt_np.ravel()).size:\n",
    "            # 正常、異常のピクセルがある場合のみ\n",
    "            fpr, tpr, thr = roc_curve(gt_np.ravel(), anomaly_map_resized_blur.ravel())\n",
    "            best_thr, best_idx = calc_roc_best_score(fpr, tpr, thr)\n",
    "            self.best_thr_pixel.append(best_thr)\n",
    "\n",
    "        self.gt_image.append(label.cpu().numpy()[0])\n",
    "        self.score_image.append(score)\n",
    "        self.img_path_list.extend(file_name)\n",
    "\n",
    "        features.clear()\n",
    "        del features\n",
    "        embedding.clear()\n",
    "        del embedding\n",
    "        del embedding_test\n",
    "\n",
    "    def test_epoch_end(self, outputs):\n",
    "        score_image = np.array(self.score_image).ravel()\n",
    "        norm_score = min_max_norm(score_image)\n",
    "        self.score_image_norm = norm_score\n",
    "\n",
    "        if self.embedding_coreset is not None:\n",
    "            del self.embedding_coreset\n",
    "        gc.collect()\n",
    "\n",
    "    def create_coreset(self, embedding_list):\n",
    "        total_embeddings = np.array(embedding_list)\n",
    "\n",
    "        # Random projection\n",
    "        # 'auto' => Johnson-Lindenstrauss lemma\n",
    "        try:\n",
    "            randomprojector = SparseRandomProjection(n_components='auto', eps=0.9)\n",
    "            randomprojector.fit(total_embeddings)\n",
    "        except Exception as ex:\n",
    "            randomprojector = None\n",
    "\n",
    "        # Coreset Subsampling\n",
    "        selector = KCenterGreedy(X=total_embeddings, y=0, seed=0)\n",
    "\n",
    "        selected_idx = selector.select_batch_torch(\n",
    "            model=randomprojector,\n",
    "            already_selected=[],\n",
    "            N=int(total_embeddings.shape[0] * self.args.coreset_sampling_ratio))\n",
    "\n",
    "        # selected_idx = selector.select_batch(\n",
    "        #     model=randomprojector,\n",
    "        #     already_selected=[],\n",
    "        #     N=int(total_embeddings.shape[0] * self.args.coreset_sampling_ratio))\n",
    "\n",
    "        embedding_coreset = total_embeddings[selected_idx]\n",
    "\n",
    "        embedding_list.clear()\n",
    "        del embedding_list\n",
    "        del total_embeddings\n",
    "        return embedding_coreset\n",
    "\n",
    "    def save_coreset(self, save_file_path):\n",
    "        try:\n",
    "            with open(save_file_path, 'wb') as f:\n",
    "                pickle.dump(\n",
    "                    {\n",
    "                        'args': self.args,\n",
    "                        'model_data': self.embedding_coreset\n",
    "                    }\n",
    "                    , f)\n",
    "                # pickle.dump(\n",
    "                #     {\n",
    "                #         'model': self.args.model,\n",
    "                #         'backbone': self.args.backbone,\n",
    "                #         'backbone_layers': self.args.backbone_layers,\n",
    "                #         'model_data': self.embedding_coreset}\n",
    "                #     , f)\n",
    "                # pickle.dump(self.embedding_coreset, f)\n",
    "        except Exception as ex:\n",
    "            raise AnodetException(f'学習済みモデルの保存に失敗しました。\\n {save_file_path}を確認してください', ex)\n",
    "\n",
    "    def test_step_other(self, batch, batch_idx):\n",
    "        x, gt, label, file_name, x_type = batch\n",
    "\n",
    "        features = self(x)\n",
    "        embedding = features_to_embedding(features)\n",
    "        embedding_test = np.array(embedding)\n",
    "\n",
    "        # score_patches, index_info = self.knn.search(embedding_test)\n",
    "\n",
    "        # score_patches = get_knn_distance_faiss(\n",
    "        #     self.embedding_coreset,\n",
    "        #     embedding_test,\n",
    "        #     k=self.args.n_neighbors,\n",
    "        #     batch_size=self.args.calc_distance_batch_size)\n",
    "\n",
    "        score_patches = get_knn_distance(\n",
    "            self.embedding_coreset,\n",
    "            embedding_test,\n",
    "            k=self.args.n_neighbors,\n",
    "            batch_size=self.args.calc_distance_batch_size)\n",
    "\n",
    "        if self.score_patches_array is None:\n",
    "            self.score_patches_array = score_patches[np.newaxis]\n",
    "        else:\n",
    "            self.score_patches_array = np.concatenate([self.score_patches_array, score_patches[np.newaxis]], axis=0)\n",
    "\n",
    "        # set results\n",
    "        gt_np = gt.cpu().numpy()[0, 0].astype(int)\n",
    "        self.gt_pixel.append(gt_np)\n",
    "        # self.gt_pixel.append(gt_np.ravel())\n",
    "        # self.gt_pixel.extend(gt_np.ravel())\n",
    "\n",
    "        self.gt_image.append(label.cpu().numpy()[0])\n",
    "        self.img_path_list.extend(file_name)\n",
    "\n",
    "        features.clear()\n",
    "        del features\n",
    "        embedding.clear()\n",
    "        del embedding\n",
    "\n",
    "    def test_epoch_other(self, outputs):\n",
    "        self.score_patches_array = min_max_norm(self.score_patches_array)\n",
    "        max_count = self.score_patches_array.shape[0]\n",
    "        for index in range(max_count):\n",
    "            score_patches = self.score_patches_array[index]\n",
    "            gt = self.gt_pixel[index]\n",
    "            self.eval_for_one_image(score_patches, gt)\n",
    "\n",
    "        if self.embedding_coreset is not None:\n",
    "            del self.embedding_coreset\n",
    "        if self.score_patches_array is not None:\n",
    "            del self.score_patches_array\n",
    "        gc.collect()\n",
    "\n",
    "    def eval_for_one_image(self, score_patches, gt):\n",
    "        # score_patches, index_info = self.knn.search(embedding_test)\n",
    "\n",
    "        # score_patches = get_knn_distance_faiss(\n",
    "        #     self.embedding_coreset,\n",
    "        #     embedding_test,\n",
    "        #     k=self.args.n_neighbors,\n",
    "        #     batch_size=self.args.calc_distance_batch_size)\n",
    "\n",
    "        # score_patches = get_knn_distance(\n",
    "        #     self.embedding_coreset,\n",
    "        #     embedding_test,\n",
    "        #     k=self.args.n_neighbors,\n",
    "        #     batch_size=self.args.calc_distance_batch_size)\n",
    "\n",
    "        # Image-level score\n",
    "        nearest_distance = score_patches[np.argmax(score_patches[:, 0])]\n",
    "        w = (1 - (np.max(np.exp(nearest_distance)) / np.sum(np.exp(nearest_distance))))\n",
    "        if math.isnan(w):\n",
    "            # distanceが大きすぎる場合の暫定処理\n",
    "            w = (1 - (np.max(np.exp(nearest_distance * (1 / 16))) / np.sum(np.exp(nearest_distance * (1 / 16)))))\n",
    "        score = w * max(score_patches[:, 0])\n",
    "\n",
    "        # pixel level anomaly map\n",
    "        reshape_size = np.sqrt(score_patches[:, 0].shape)[0].astype(np.int)\n",
    "        anomaly_map = score_patches[:, 0].reshape((reshape_size, reshape_size))\n",
    "        anomaly_map_resized = cv2.resize(anomaly_map, (self.args.input_size, self.args.input_size))\n",
    "        anomaly_map_resized_blur = gaussian_filter(anomaly_map_resized, sigma=4)\n",
    "        anomaly_map_norm = min_max_norm(anomaly_map_resized_blur)\n",
    "\n",
    "        # set results\n",
    "        # gt_np = gt.cpu().numpy()[0, 0].astype(int)\n",
    "        # self.gt_pixel.append(gt_np)\n",
    "        # # self.gt_pixel.append(gt_np.ravel())\n",
    "        # # self.gt_pixel.extend(gt_np.ravel())\n",
    "\n",
    "        self.score_pixel.append(anomaly_map_resized_blur)\n",
    "        # self.score_pixel.append(anomaly_map_resized_blur)\n",
    "        # self.score_pixel.append(anomaly_map_resized_blur.ravel())\n",
    "        # self.score_pixel.extend(anomaly_map_resized_blur.ravel())\n",
    "\n",
    "        if 1 < np.unique(gt.ravel()).size:\n",
    "            # 正常、異常のピクセルがある場合のみ\n",
    "            fpr, tpr, thr = roc_curve(gt.ravel(), anomaly_map_resized_blur.ravel())\n",
    "            best_thr, best_idx = calc_roc_best_score(fpr, tpr, thr)\n",
    "            self.best_thr_pixel.append(best_thr)\n",
    "\n",
    "        # self.gt_image.append(label.cpu().numpy()[0])\n",
    "        self.score_image.append(score)\n",
    "        # self.img_path_list.extend(file_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bc899c62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from distutils.util import strtobool\n",
    "\n",
    "def get_args():\n",
    "    parser = argparse.ArgumentParser(description='ANOMALYDETECTION')\n",
    "    parser.add_argument('--phase', choices=['train', 'test'], default='train')\n",
    "    parser.add_argument('--backbone', choices=['WideResNet50',\n",
    "                                               'WideResNet101',\n",
    "                                               'EfficientNetB5', \n",
    "                                               'EfficientNetB7'],\n",
    "                        default='WideResNet50')\n",
    "    parser.add_argument('--dataset_path', default='../dataset', type=str)\n",
    "    parser.add_argument('--project_root_path', default='./results', type=str)\n",
    "    parser.add_argument('--categories', default='', nargs='*', type=str)\n",
    "    parser.add_argument('--num_epochs', default=1, type=int)\n",
    "    parser.add_argument('--batch_size', default=32, type=int)\n",
    "    parser.add_argument('--load_size', default=256, type=int)\n",
    "    parser.add_argument('--input_size', default=224, type=int)\n",
    "    parser.add_argument('--coreset_sampling_ratio', default=0.01, type=float)\n",
    "    parser.add_argument('--kernel_size', default=3, type=int, help='average poolingのkernel size')\n",
    "    parser.add_argument('--stride', default=1, type=int, help='average poolingのstride')\n",
    "    parser.add_argument('--padding', default=1, type=int, help='average poolingのpadding')\n",
    "    parser.add_argument('--coreset_save_root', type=str, default='embeddings')\n",
    "    parser.add_argument('--save_anomaly_map', default=True)\n",
    "    parser.add_argument('--n_neighbors', type=int, default=9)\n",
    "    parser.add_argument('--calc_distance_batch_size', type=int, default=512)\n",
    "    parser.add_argument('--seed', type=int, default=8)\n",
    "    parser.add_argument('--gpus', type=int, default=-1)\n",
    "    parser.add_argument(\"--num_workers\", type=int, default=0,\n",
    "                        help=\"データを読み込む際に使用するスレッド数を指定\")\n",
    "    parser.add_argument(\"--is_plot_pixel_graph\", type=strtobool, default=True, help=\"\")\n",
    "    parser.add_argument(\"--is_force_train\", type=strtobool, default=False, help=\"\")\n",
    "    parser.add_argument(\"--random_crop\", type=strtobool, default=False, help=\"\")\n",
    "    parser.add_argument('--iter', type=int, default=1)\n",
    "    parser.add_argument('--comment', type=str, default='comment')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "    return args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68120f78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = get_args()\n",
    "\n",
    "category = 'wcvt'\n",
    "class Args:\n",
    "    data = './data/penn'\n",
    "    backbone = 'WideResNet50'\n",
    "    num_epochs = 1\n",
    "    batch_size = 16\n",
    "    input_size = 224\n",
    "    load_size=256\n",
    "    is_plot_pixel_graph = 1\n",
    "    is_force_train = 0\n",
    "    kernel_size = 3\n",
    "    stride = 1\n",
    "    padding = 1\n",
    "    coreset_sampling_ratio=0.01\n",
    "    random_crop=0\n",
    "    iter=1\n",
    "    n_neighbors=9\n",
    "    calc_distance_batch_size=512\n",
    "    categories = category\n",
    "    \n",
    "args = Args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f1a3a04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/pytorch/vision/archive/v0.8.2.zip\" to C:\\Users\\innat/.cache\\torch\\hub\\v0.8.2.zip\n"
     ]
    }
   ],
   "source": [
    "model = PatchCore(args, category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dde2669e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PatchCore(\n",
       "  (inv_normalize): Normalize(mean=[-2.1179039301310043, -2.0357142857142856, -1.5921568627450982], std=[4.366812227074235, 4.464285714285714, 3.9215686274509802])\n",
       "  (backbone_model): WideResNet50(\n",
       "    (pretrained_model): ResNet(\n",
       "      (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "      (layer1): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(128, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer2): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(256, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer3): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(512, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (5): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(512, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (layer4): Sequential(\n",
       "        (0): Bottleneck(\n",
       "          (conv1): Conv2d(1024, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "          (downsample): Sequential(\n",
       "            (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "            (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "        (1): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Bottleneck(\n",
       "          (conv1): Conv2d(2048, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv2): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "          (bn2): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (conv3): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (relu): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "      (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "      (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (criterion): MSELoss()\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b6311493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 28, 28])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand((1, 3, 224, 224)))[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "350d10fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1024, 14, 14])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(torch.rand((1, 3, 224, 224)))[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d8f82a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "pytorch-gpu.1-11.m91",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-11:m91"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
